name: Pull request
on: pull_request
permissions:
  contents: read
  pull-requests: write

jobs:
  size:
    runs-on: ubuntu-latest
    env:
      CI_JOB_NUMBER: 1
      THEME: cpr
    steps:
      - uses: actions/checkout@v4
      - uses: andresz1/size-limit-action@v1
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}

  lhci-desktop:
    name: Lighthouse Desktop
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Use Node.js 22.12.0
        uses: actions/setup-node@v4
        with:
          node-version: 22.12.0
      - run: npm install
      - run: cp .env.example .env
      - run: npm run build
      - name: install Lighthouse CI
        run: npm install -g @lhci/cli@0.14.x
      - name: run Lighthouse Desktop
        # The --baseHash parameter compares the current commit (the one being tested) against the specified base hash.
        # E.g., if your PR branch has commit abc123, and the main branch has commit def456,
        # --baseHash=def456 tells Lighthouse: "Compare abc123 against def456"
        run: lhci autorun --collect.settings.preset=desktop --baseHash=${{ github.event.pull_request.base.sha }} 2>&1 | tee lighthouse-output.log
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}
          LHCI_BASE_HASH: ${{ github.event.pull_request.base.sha }}
      - name: Extract build ID and check for performance regressions (Desktop)
        run: |
          BUILD_ID=$(grep "Saving CI build" lighthouse-output.log | grep -o '[a-f0-9]\{8\}-[a-f0-9]\{4\}-[a-f0-9]\{4\}-[a-f0-9]\{4\}-[a-f0-9]\{12\}' | head -1)
          if [ -n "$BUILD_ID" ]; then
            echo "LHCI_BUILD_ID=$BUILD_ID" >> $GITHUB_ENV
            echo "üîç Extracted build ID: $BUILD_ID"
            node scripts/check-lighthouse-regression.js
          else
            echo "‚ö†Ô∏è  Could not extract build ID from Lighthouse output"
            echo "üìÑ Lighthouse output:"
            cat lighthouse-output.log
            exit 0
          fi
        env:
          LHCI_BASE_HASH: ${{ github.event.pull_request.base.sha }}
          LHCI_BUILD_ID: ${{ env.LHCI_BUILD_ID }}

  lhci-mobile:
    name: Lighthouse Mobile
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Use Node.js 22.12.0
        uses: actions/setup-node@v4
        with:
          node-version: 22.12.0
      - run: npm install
      - run: cp .env.example .env
      - run: npm run build
      - name: install Lighthouse CI
        run: npm install -g @lhci/cli@0.14.x
      - name: run Lighthouse Mobile
        # The --baseHash parameter compares the current commit (the one being tested) against the specified base hash.
        # E.g., if your PR branch has commit abc123, and the main branch has commit def456,
        # --baseHash=def456 tells Lighthouse: "Compare abc123 against def456"
        run: lhci autorun --baseHash=${{ github.event.pull_request.base.sha }} 2>&1 | tee lighthouse-output.log
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}
          LHCI_BASE_HASH: ${{ github.event.pull_request.base.sha }}
      - name: Extract build ID and check for performance regressions (Mobile)
        run: |
          BUILD_ID=$(grep "Saving CI build" lighthouse-output.log | grep -o '[a-f0-9]\{8\}-[a-f0-9]\{4\}-[a-f0-9]\{4\}-[a-f0-9]\{4\}-[a-f0-9]\{12\}' | head -1)
          if [ -n "$BUILD_ID" ]; then
            echo "LHCI_BUILD_ID=$BUILD_ID" >> $GITHUB_ENV
            echo "üîç Extracted build ID: $BUILD_ID"
            node scripts/check-lighthouse-regression.js
          else
            echo "‚ö†Ô∏è  Could not extract build ID from Lighthouse output"
            echo "üìÑ Lighthouse output:"
            cat lighthouse-output.log
            exit 0
          fi
        env:
          LHCI_BASE_HASH: ${{ github.event.pull_request.base.sha }}
          LHCI_BUILD_ID: ${{ env.LHCI_BUILD_ID }}

  percy:
    runs-on: ubuntu-latest
    env:
      THEME: cpr
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: 22.12.0
      - run: npm install
      - run: cp .env.example .env
      - run: npm run build
        env:
          NODE_ENV: production
      - run: npm run start &
      - run: |
          echo "Waiting for server to start..."
          npx wait-on http://localhost:3000
      - run: npx percy snapshot snapshots.js
        env:
          PERCY_TOKEN: ${{ secrets.PERCY_TOKEN }}
      - if: always()
        run: kill $(lsof -t -i:3000) || true

  code-quality:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: 22.12.0
      - run: npm install
      - uses: trunk-io/trunk-action@v1
        with:
          arguments: --ci
      - run: npm run type-check

    permissions:
      # For trunk to post annotations
      checks: write
      # For repo checkout
      contents: read

  test:
    timeout-minutes: 15
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: 22.12.0
      - run: npm install
      - run: cp .env.example .env
      - run: npm run build
        env:
          NODE_ENV: production
      - run: npm run test
      - name: Upload results
        # Run this step even if the test step ahead fails
        if: ${{ !cancelled() }}
        uses: trunk-io/analytics-uploader@main
        with:
          junit-paths: "**/vitest.xml"
          org-slug: ${{ secrets.TRUNK_ORG_SLUG }}
          token: ${{ secrets.TRUNK_TOKEN }}
        continue-on-error: true

  test-e2e:
    timeout-minutes: 15
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: 22.12.0
      - run: npm ci
      - run: cp .env.example .env
      - run: npm run build
        env:
          NODE_ENV: production
      - run: npx playwright install --with-deps
      - run: npx playwright test
      - uses: actions/upload-artifact@v4
        if: ${{ !cancelled() }}
        with:
          name: playwright-report
          path: test-results/
          retention-days: 30
      - name: Upload Test Result
        # Upload the results even if the tests fails to Trunk.io
        if: ${{ !cancelled() }}
        continue-on-error: true
        uses: trunk-io/analytics-uploader@main
        with:
          junit-paths: "**/playwright.xml"
          org-slug: ${{ secrets.TRUNK_ORG_SLUG }}
          token: ${{ secrets.TRUNK_TOKEN }}
